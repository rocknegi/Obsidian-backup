### Basics
- Many data chunks
- Map function on each of the chunks
- Map process outputs data with keys => Partitions based on keys
- Aggregate (fold/reduce) mapped data per key
- Output is written to (distributed) file system
- E.g., count number occurrences of each terms in
set of documents.
- ![[Pasted image 20230903121056.png]]
- ![[Pasted image 20230903121256.png]]
- <iframe width="480" height="240" src="https://www.youtube.com/embed/cHGaQz0E7AU" title="Map Reduce explained with example | System Design" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
- idea 
	- 1. **Map**:
	    - **Mapping Phase**: In this phase, input data is divided into chunks or splits, and a user-defined function called the "Mapper" is applied to each chunk independently. The Mapper processes each piece of data and produces a set of intermediate key-value pairs.
	    - **Parallel Processing**: Mapping is inherently parallel because each chunk can be processed independently by different nodes in a cluster. This parallelism is crucial for processing large datasets efficiently.
	1. **Shuffle and Sort**:
    	    - After the Map phase, the framework groups together all the intermediate key-value pairs with the same key from different mappers. This process is called the "Shuffle and Sort" phase.
	    - The goal is to collect all the values associated with the same key so that they can be processed together in the next phase.
	1. **Reduce**:
    	    - **Reducing Phase**: In this phase, a user-defined function called the "Reducer" is applied to each group of intermediate key-value pairs with the same key. The Reducer processes the values associated with a key and produces the final output key-value pairs.
	    - **Aggregation**: The Reduce phase typically involves some form of aggregation or summarization of data, such as counting, summing, averaging, or any other operation required by the application.
	1. **Output**:
	    - The final output of the MapReduce job is a set of key-value pairs that represent the results of the computation.
- ![[Pasted image 20230922000125.png]] x "might" be there because of false positives. Hashing collision can be there. Bloom filter is an approximate representation.