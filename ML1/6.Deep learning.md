### Neural network basics 
-	<iframe width="480" height="240" src="https://www.youtube.com/embed/aircAruvnKk?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
-	Each neuron consists of 4 parts 
	-	input 
	-	weight 
	-	bias 
	-	output 
-	The input, is multiplied by the weight, then is added to the bias, and finally the result is the output The "learning" process, in the case of this one neuron, is to change the values of weight and bias to make sure the input results in the desired output. 
-	![[Pasted image 20220613180720.png]]
-	![[Pasted image 20220613180737.png]]

	### Sigmoid Function 
	- ![[Pasted image 20220613180534.png]]
	- Close to 0 for more -ve numbers
	- Close to 1 for more +ve numbers

	### ReLU 
	- ![[Pasted image 20220613180824.png]]
	- sigmoid is slower 

### CNN 
- <iframe width="480" height="240" src="https://www.youtube.com/embed/FmpDIaiMIeA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
- ![[Pasted image 20220613221616.png]]

###  backpropagation
- <iframe width="480" height="240" src="https://www.youtube.com/embed/Ilg3gGewQ5U?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi" title="What is backpropagation really doing? | Chapter 3, Deep learning" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>